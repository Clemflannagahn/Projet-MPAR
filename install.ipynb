{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdp\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import graphviz as gv\n",
    "import imageio\n",
    "import os\n",
    "import imageio.v2 as imageio\n",
    "\n",
    "class States():\n",
    "    def __init__(self, state,transitions_with_action, transitions_without_action):\n",
    "        \"\"\"\n",
    "        Initialisation des états de la chaine de markov\n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        state : str\n",
    "            Nom de l'état (S0...)\n",
    "        reward : int\n",
    "            Récompense de l'état\n",
    "        transitions_with_action : dict\n",
    "            Dictionnaire de l'ensemble des transitions avec action\n",
    "        transitions_without_action : dict\n",
    "            Dictionnaire de l'ensemble des transitions sans action\n",
    "        \"\"\"\n",
    "        self.state = state\n",
    "        self.reward = 0 # récompense de l'état\n",
    "        self.transitions_without_action = {}\n",
    "        self.transitions_with_action = {}\n",
    "\n",
    "        sans_action = True # on crée ce booléen pour vérifier qu'il n'y a pas de transition avec action ensuite\n",
    "        for transition in transitions_without_action:\n",
    "            # on parcours l'ensemble des transitions\n",
    "            transi_active = transitions_without_action[transition]\n",
    "            if transi_active[\"from\"]==self.state: # on vérifie si l'état de départ est l'état actif\n",
    "                sans_action = False\n",
    "                self.transitions_without_action[\"targets\"] = transi_active[\"targets\"]\n",
    "                self.transitions_without_action[\"weights\"] = transi_active[\"weights\"]\n",
    "\n",
    "        for transition in transitions_with_action:\n",
    "            transi_active = transitions_with_action[transition]\n",
    "            if transi_active[\"from\"]==self.state and sans_action == True:\n",
    "                # les clés dans transition_with_action sont les actions et les valeurs des dict des états cibles et leurs poids\n",
    "                self.transitions_with_action[transi_active[\"action\"]] = {\"targets\" : transi_active[\"targets\"], \"weights\" : transi_active[\"weights\"]}\n",
    "            elif transi_active[\"from\"]==self.state and sans_action == False:\n",
    "                print(\"\\nWarning : l'état\", self.state, \"comporte des transitions avec et sans action\")\n",
    "                print(\"Il est donc impossible de déterminer la transition à effectuer, il faut revoir la modélisation \\n\")\n",
    "                break\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"State : {self.state} \\n State reward {self.reward} \\n Transitions without action : {self.transitions_without_action} \\n Transitions with action : {self.transitions_with_action}\")\n",
    "\n",
    "\n",
    "class markov():\n",
    "    def __init__(self, fichier_mdp):\n",
    "        \"\"\"\n",
    "        Initialisation de la chaine de markov\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        fichier_mdp : str\n",
    "            Nom du fichier contenant la modélisation de la chaine de markov\n",
    "        \"\"\"\n",
    "        ! python mdp.py < {fichier_mdp} # On lance le fichier mdp.py avec la modélisation voulue\n",
    "        # On lit le .pickle des données que l'on souhaitent récupérer\n",
    "        def read_list(nom_liste):\n",
    "            # for reading also binary mode is important\n",
    "            with open(nom_liste, 'rb') as fp:\n",
    "                liste = pickle.load(fp)\n",
    "                return liste\n",
    "\n",
    "        L = read_list(\"liste_donnees\")\n",
    "        # print('Données récupérées', L)\n",
    "        states, actions, transitions_with_action, transitions_without_action = L['States'], L['Actions'], L['Transitions_with_action'], L['Transitions_without_action']\n",
    "        print(\"-\"*50)\n",
    "        print(\" \")\n",
    "         \n",
    "        # on peut alors initialiser les éléments de la chaine de markov\n",
    "        self.states = {}\n",
    "        self.liste_states = states\n",
    "        self.actions = actions\n",
    "        self.transitions_with_action = transitions_with_action\n",
    "        self.transitions_without_action = transitions_without_action\n",
    "\n",
    "        for state in states:\n",
    "            self.states[f\"{state}\"] = States(state, transitions_with_action, transitions_without_action)\n",
    "        \n",
    "        print(\" \")\n",
    "        print(\"Souhaitez-vous que les problèmes détéctés prochainement soient résolus automatiquement si cela est possible? (y/n)\")\n",
    "        time.sleep(0.5)\n",
    "        reponse = input()\n",
    "        if reponse == \"y\":\n",
    "            markov.parsing(self, states,reponse = True) # on vérifie qu'on a pas de problèmes de parsing\n",
    "        else:\n",
    "            markov.parsing(self, states,reponse = False) # on vérifie qu'on a pas de problèmes de parsing\n",
    "\n",
    "        print(\"Souhaitez-vous ajouter des récompenses aux états ? (y/n)\")\n",
    "        time.sleep(0.5)\n",
    "        reponse = input()\n",
    "        if reponse == \"y\":\n",
    "            for state in self.states :\n",
    "                etat = self.states[state]\n",
    "                reward = markov.affichage_etat(self, etat, reward = True)\n",
    "                etat.reward = float(reward)\n",
    "        \n",
    "        print(\" \")\n",
    "        print(\"Pour lancer un parcours, lancez M.parcours()\")\n",
    "        \n",
    "    def parsing(self, states, resolution):\n",
    "        \"\"\"\n",
    "        On réalise différents tests pour vérifier que la chaine de markov (ou la MDP) est correctement définie\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        states : list\n",
    "            Liste des états de la chaines (avec possiblement des doublons)\n",
    "        resolution : bool\n",
    "            Booléen qui permet de savoir si on veut résoudre les problèmes détéctés automatiquement si possible\n",
    "        \"\"\"\n",
    "        # On concatène les transitions avec et sans action pour plus de simplicité pour les test\n",
    "        Warning = False # passe à True si on a un warning\n",
    "\n",
    "        all_transitions = []\n",
    "        transitions_without_action = []\n",
    "        transitions_with_action = []\n",
    "        for elem in self.transitions_without_action:\n",
    "            transitions_without_action.append(self.transitions_without_action[elem])\n",
    "            all_transitions.append(self.transitions_without_action[elem])\n",
    "        for elem in self.transitions_with_action:\n",
    "            transitions_with_action.append(self.transitions_with_action[elem])\n",
    "            all_transitions.append(self.transitions_with_action[elem])\n",
    "\n",
    "        # On vérifie que les états déclarés sont utilisés et qu'un état utilisé dans des transitions est déclaré\n",
    "        used_states = []\n",
    "        for transitions in all_transitions:\n",
    "            if transitions[\"from\"] not in self.states:\n",
    "                print(f\"Warning : l'état {transitions['from']} est utilisé dans une transition mais n'est pas déclaré\")\n",
    "                Warning = True\n",
    "                if resolution:\n",
    "                    # On rajoute l'état manquant\n",
    "                    self.states[transitions[\"from\"]] = States(transitions[\"from\"], self.transitions_with_action, self.transitions_without_action)\n",
    "\n",
    "            used_states.append(transitions[\"from\"])\n",
    "            used_states.append(transitions[\"targets\"])\n",
    "            for target in transitions[\"targets\"]:\n",
    "                if target not in self.states:\n",
    "                    print(f\"Warning : l'état {target} est utilisé dans une transition mais n'est pas déclaré\")\n",
    "                    Warning = True\n",
    "                    if resolution:\n",
    "                        # On rajoute l'état manquant\n",
    "                        self.states[target] = States(target, self.transitions_with_action, self.transitions_without_action)\n",
    "        for state in self.states:\n",
    "            if state not in used_states:\n",
    "                print(f\"Warning : l'état {state} est déclaré mais n'est pas utilisé\")\n",
    "                Warning = True\n",
    "                if resolution:\n",
    "                    # On rajoute une transition de l'état vers lui même pour éviter les erreurs\n",
    "                    self.transitions_without_action[f\"{state}\"] = {0: {'from': f'{state}', 'targets': [f\"{state}\"], 'weights': [10]}}\n",
    "\n",
    "        # On vérifie qu'un état n'est pas déclaré plusieurs fois\n",
    "        if len(states) != len(self.states): # self.states supprime automatiquement les doublons\n",
    "            print(\"Warning : un état est déclaré plusieurs fois\")\n",
    "            Warning = True\n",
    "\n",
    "        # On vérifie qu'un état possède bien une transition de sortie\n",
    "        etats_sans_sortie = []\n",
    "        dict_etats = self.states\n",
    "        bool_etat_sans_sortie = False\n",
    "        for state in dict_etats:\n",
    "            if dict_etats[state].transitions_without_action == {} and dict_etats[state].transitions_with_action == {}:\n",
    "                etats_sans_sortie.append(state)\n",
    "                bool_etat_sans_sortie = True\n",
    "        if bool_etat_sans_sortie == True:\n",
    "            print(\"Warning : les états suivants n'ont pas de transition de sortie : \", etats_sans_sortie)\n",
    "\n",
    "        # On vérifie que les actions ne sont pas déclarées plusieurs fois\n",
    "        actions_uniques = set(self.actions)\n",
    "        if len(actions_uniques) != len(self.actions):\n",
    "            print(\"Warning : une action est déclarée plusieurs fois\")\n",
    "            Warning = True\n",
    "    \n",
    "        # On vérifie qu'une action déclarée est utilisée\n",
    "        actions_utilisés = []\n",
    "        for transitions in transitions_with_action:\n",
    "            actions_utilisés.append(transitions[\"action\"])\n",
    "        actions_utilisés = set(actions_utilisés) # on enlève les doublons\n",
    "        if len(actions_utilisés) != len(self.actions):\n",
    "            print(\"Warning : une action est déclarée mais n'est pas utilisée\")\n",
    "            Warning = True\n",
    "\n",
    "        # On vérifie que les actions utilisées sont déclarées\n",
    "        for action in actions_utilisés:\n",
    "            if action not in self.actions:\n",
    "                print(f\"Warning : l'action {action} est utilisée mais n'est pas déclarée\")\n",
    "                Warning = True\n",
    "\n",
    "        if Warning :\n",
    "            print(\"\\n Écrire ok pour contiuer\")\n",
    "            print(\"-\"*25 + \"\\n\")\n",
    "            while True:\n",
    "                rep = input()\n",
    "                if rep == \"ok\":\n",
    "                    break\n",
    "            \n",
    "    def affichage_etat(self,etat_actif,choix = False, reward = False):\n",
    "        \"\"\"\n",
    "        Affiche proprement l'état actif de la chaine de markov et permet de choisir une action le cas échéant\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        etat_actif : état de la chaine de markov\n",
    "            Etat actif de la chaine de markov\n",
    "        choix : bool\n",
    "            Si on doit afficher des choix pour des actions\n",
    "        \"\"\"\n",
    "        nom = etat_actif.state\n",
    "        print(\"-\"*50)\n",
    "        chaine_nom = f\"| Etat actif : {nom}\"\n",
    "        l = len(chaine_nom)\n",
    "        print(chaine_nom + \" \"*(49-l) + \"|\")\n",
    "        if choix :\n",
    "            chaine_choix = f\"| choix possibles pour l'état {etat_actif.state}:\"\n",
    "            l = len(chaine_choix)\n",
    "            print(chaine_choix + \" \"*(49-l) + \"|\")\n",
    "\n",
    "            chaine_transi = f\"| {list(etat_actif.transitions_with_action.keys())}\"\n",
    "            l = len(chaine_transi)\n",
    "            print(chaine_transi + \" \"*(49-l) + \"|\")\n",
    "\n",
    "            chaine_action = f\"| choix de l'action  :\"\n",
    "            l = len(chaine_action)\n",
    "            print(chaine_action + \" \"*(49-l) + \"|\")\n",
    "            time.sleep(0.5)\n",
    "            choix = input()\n",
    "            while choix not in list(etat_actif.transitions_with_action.keys()): # on vérifie que l'action choisie est valide\n",
    "                choix = input()\n",
    "                if choix == \"stop\": # permet d'arrêter le programme à la main\n",
    "                    break\n",
    "            chaine_choix = f\"| Vous avez choisi l'action {choix}\"\n",
    "            l = len(chaine_choix)\n",
    "            print(chaine_choix + \" \"*(49-l) + \"|\")\n",
    "\n",
    "        elif reward:\n",
    "            chaine_choix = f\"| Récompense pour l'état {etat_actif.state}:\"\n",
    "            l = len(chaine_choix)\n",
    "            print(chaine_choix + \" \"*(49-l) + \"|\")\n",
    "            time.sleep(0.5)\n",
    "            choix = input()\n",
    "            chaine_rec = f\"| Vous avez choisi : {choix}\"\n",
    "            l = len(chaine_rec)\n",
    "            print(chaine_rec + \" \"*(49-l) + \"|\")\n",
    "\n",
    "            \n",
    "        print(\"-\"*50)\n",
    "        print(\"\\n\")   \n",
    "        return choix    \n",
    "\n",
    "    def parcours(self, file_name=\"visu_parcours\"): # on parcours la chaine (en faisant N étapes)\n",
    "        \"\"\" \n",
    "        On parcours la chaine en faisant N étapes\n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        file_name : str\n",
    "            Nom du fichier de sauvegarde de la vidéo\n",
    "        \"\"\"\n",
    "        positionnel = False\n",
    "        n_pos = False\n",
    "        without_action = False\n",
    "        \n",
    "        print(\"Quel mode de parcours voulez-vous ?\")\n",
    "        print(\"1 : sans actions\")\n",
    "        print(\"2 : avec adversaire positionnel\")\n",
    "        print(\"3 : avec adversaire non positionnel\")\n",
    "        time.sleep(0.5)\n",
    "        choix_parcours = input()\n",
    "        while choix_parcours not in [\"1\",\"2\",\"3\"]:\n",
    "            choix_parcours = input()\n",
    "        if choix_parcours == \"1\":\n",
    "            without_action = True\n",
    "        elif choix_parcours == \"2\":\n",
    "            positionnel = True\n",
    "        elif choix_parcours == \"3\":\n",
    "            n_pos = True\n",
    "        \n",
    "        print(\"Combien d'étapes voulez-vous faire ?\")\n",
    "        time.sleep(0.5)\n",
    "        N = int(input())\n",
    "\n",
    "        etat_initial = self.liste_states[0] #état initial : premier élément\n",
    "        etat_actif = self.states[etat_initial] # on prend l'objet correspondant à l'état initial\n",
    "        reward_total = 0\n",
    "        \n",
    "        self.afficher(etat = etat_initial, file_name='image0')\n",
    "        images = []\n",
    "        images.append(imageio.imread('image0'+'.png'))\n",
    "\n",
    "        if without_action:\n",
    "        # On vérifie qu'on ne choisit pas le mode \"sans actions\" alors qu'il y en a\n",
    "            for state in self.states:\n",
    "                if len(self.states[state].transitions_with_action) != 0:\n",
    "                    print(\"Error : il y a des transitions avec actions, il faut choisir le mode avec actions\")\n",
    "                    return\n",
    "\n",
    "\n",
    "            for i in range(N):\n",
    "                markov.affichage_etat(self, etat_actif)\n",
    "                # print(etat_actif.state) # on affiche l'état en cours\n",
    "                poids = etat_actif.transitions_without_action[\"weights\"]\n",
    "                poids_total = np.sum(poids)\n",
    "                poids = poids/poids_total # on normalise les poids pour qu'ils soient entre 0 et 1\n",
    "                poids = np.cumsum(poids) # on fait la somme cumulée des poids, afin de pouvoir faire un tirage aléatoire (il ne faut pas que par exemple les deux probas soient de 0.5, il en faut une de 0.5 et l'autre de 1)\n",
    "\n",
    "                choix = random.random() # tirage aléatoire entre 0 et 1\n",
    "\n",
    "                for j in range(len(poids)): # on recherche l'état cible\n",
    "                    if choix <= poids[j]:\n",
    "                        reward_total += etat_actif.reward\n",
    "                        etat_actif = self.states[etat_actif.transitions_without_action[\"targets\"][j]]\n",
    "                        break\n",
    "                self.afficher(etat = etat_actif.state, file_name='image'+str(i+1))\n",
    "                images.append(imageio.imread('image'+str(i+1)+'.png'))\n",
    "            # create gif\n",
    "            imageio.mimsave(file_name+'.gif', images, fps=3)\n",
    "            for i in range(N+1):\n",
    "                os.remove('image'+str(i)+'.png')\n",
    "\n",
    "        elif positionnel == True or n_pos == True: # adversaire positionnel\n",
    "            if positionnel :\n",
    "                print(\"Choix d'un adversaire positionnel\")\n",
    "                adv_pos = {} # contient pour chaque état, le choix de l'adversaire\n",
    "                for state in self.states :\n",
    "                    etat = self.states[state]\n",
    "                    if etat.transitions_with_action != {} : # si l'état possèdes des transitions avec actions\n",
    "                        action = markov.affichage_etat(self, etat, choix = True)\n",
    "                        adv_pos[state] = action\n",
    "\n",
    "            for i in range(N):\n",
    "                if etat_actif.transitions_with_action == {} : # si l'état n'a pas de transitions avec actions :\n",
    "                    markov.affichage_etat(self, etat_actif)\n",
    "                    poids = etat_actif.transitions_without_action[\"weights\"]\n",
    "\n",
    "                    poids_total = np.sum(poids)\n",
    "                    poids = poids/poids_total # on normalise les poids pour qu'ils soient entre 0 et 1\n",
    "                    poids = np.cumsum(poids) # on fait la somme cumulée des poids, afin de pouvoir faire un tirage aléatoire (il ne faut pas que par exemple les deux probas soient de 0.5, il en faut une de 0.5 et l'autre de 1)\n",
    "\n",
    "                    choix = random.random() # tirage aléatoire entre 0 et 1\n",
    "\n",
    "                    for j in range(len(poids)): # on recherche l'état cible\n",
    "                        if choix <= poids[j]:\n",
    "                            reward_total += etat_actif.reward\n",
    "                            etat_actif = self.states[etat_actif.transitions_without_action[\"targets\"][j]]\n",
    "                            break\n",
    "                else :\n",
    "                    if n_pos == True :\n",
    "                        action_choisie = markov.affichage_etat(self, etat_actif, choix =True)\n",
    "                    else :\n",
    "                        action_choisie = adv_pos[etat_actif.state]\n",
    "                        print(f\"Action choisie : {action_choisie}\")\n",
    "                        markov.affichage_etat(self, etat_actif)\n",
    "                    poids = etat_actif.transitions_with_action[action_choisie][\"weights\"] # on ne prend que les poids de l'action choisie par l'adversaire\n",
    "                    poids_total = np.sum(poids)\n",
    "                    poids = poids/poids_total # on normalise les poids pour qu'ils soient entre 0 et 1\n",
    "                    poids = np.cumsum(poids) # on fait la somme cumulée des poids, afin de pouvoir faire un tirage aléatoire (il ne faut pas que par exemple les deux probas soient de 0.5, il en faut une de 0.5 et l'autre de 1)\n",
    "\n",
    "                    choix = random.random() # tirage aléatoire entre 0 et 1\n",
    "\n",
    "                    for j in range(len(poids)): # on recherche l'état cible\n",
    "                        if choix <= poids[j]:\n",
    "                            reward_total += etat_actif.reward\n",
    "                            etat_actif = self.states[etat_actif.transitions_with_action[action_choisie][\"targets\"][j]]\n",
    "                            break\n",
    "                        \n",
    "                self.afficher(etat = etat_actif.state, file_name='image'+str(i+1))\n",
    "                images.append(imageio.imread('image'+str(i+1)+'.png'))\n",
    "            # create gif\n",
    "            imageio.mimsave(file_name+'.gif', images, fps=3)\n",
    "            for i in range(N+1):\n",
    "                os.remove('image'+str(i)+'.png')\n",
    "            for i in range(N+1):\n",
    "                os.remove('image'+str(i))\n",
    "                \n",
    "        print(f\"Reward total : {reward_total} (si aucun reward n'a été donné, le reward total est de 0)\")\n",
    "        print(\"Le graphique est visible dans le fichier visu_parcours.gif\")\n",
    "\n",
    "    \n",
    "    def afficher(self, etat = \"default\", file_name = \"graph\"):\n",
    "        \n",
    "        \"\"\"Fonction qui permet de représenter le graphe de la chaine de Markov avec ou sans action. Dans le mode \"default\", le graphe de base est affiché.\n",
    "        Dans le mode \"etat\", on peut choisir un état et il sera mis en évidence en étant de couleur bleue.\n",
    "         \"\"\"\n",
    "    \n",
    "        # On récupère les données\n",
    "        States = self.states\n",
    "        Actions = self.actions\n",
    "        Transitions_with_action = self.transitions_with_action\n",
    "        Transitions_without_action = self.transitions_without_action\n",
    "\n",
    "        # On crée le graphique\n",
    "        G = gv.Digraph(format='png')\n",
    "\n",
    "        if etat == \"default\":\n",
    "            for state in States:\n",
    "                G.node(state)\n",
    "        else:\n",
    "            for state in States:\n",
    "                if state == etat:\n",
    "                    G.node(state, color = 'blue', style = 'filled')\n",
    "                else:\n",
    "                    G.node(state)\n",
    "        \n",
    "        #On ajoute les actions\n",
    "        for actions in Actions:\n",
    "            G.node(actions, shape = 'point')\n",
    "            \n",
    "        for transition in Transitions_with_action:\n",
    "            G.edge(Transitions_with_action[transition]['from'], Transitions_with_action[transition]['action'], label=str(Transitions_with_action[transition]['action']), color = 'red')\n",
    "        \n",
    "\n",
    "        # On ajoute les transitions sans action\n",
    "        for transition in Transitions_without_action:\n",
    "            for i in range(len(Transitions_without_action[transition]['targets'])):\n",
    "                G.edge(Transitions_without_action[transition]['from'],Transitions_without_action[transition]['targets'][i], label = str(Transitions_without_action[transition]['weights'][i])) \n",
    "\n",
    "        # On ajoute les transitions avec action\n",
    "        for transition in Transitions_with_action:\n",
    "            for i in range(len(Transitions_with_action[transition]['targets'])):\n",
    "                G.edge(Transitions_with_action[transition]['action'],Transitions_with_action[transition]['targets'][i], label = str(Transitions_with_action[transition]['weights'][i]))\n",
    "        \n",
    "        G.render(file_name, view=False)\n",
    "    \n",
    "    def simulation_random(self, n_iter, mode_adv = \"random\", file_name = \"simulation_random\" ):\n",
    "        \"\"\" Fonction qui permet de simuler une chaine de Markov avec ou sans action. On peut choisir le nombre d'itération, l'état initial et le mode de l'adversaire.\n",
    "        Pour l'instant, seul le mode \"random\" est disponible.\"\"\"\n",
    "        \n",
    "        current_state = self.liste_states[0] #état initial : premier élément\n",
    "        States = self.states\n",
    "        Actions = self.actions\n",
    "        Transitions_with_action = self.transitions_with_action\n",
    "        Transitions_without_action = self.transitions_without_action\n",
    "        self.afficher(etat = current_state, file_name='image0')\n",
    "        reward_total = 0\n",
    "        images = []\n",
    "        if mode_adv == \"random\":\n",
    "            for i in range(n_iter):\n",
    "                    actions_possibles = []\n",
    "                    for transitions in Transitions_with_action:\n",
    "                        if Transitions_with_action[transitions]['from'] == current_state:\n",
    "                            actions_possibles.append(Transitions_with_action[transitions]['action'])\n",
    "                    if len(actions_possibles) == 0:\n",
    "                        for transitions in Transitions_without_action:\n",
    "                            if Transitions_without_action[transitions]['from'] == current_state:\n",
    "                                poids = Transitions_without_action[transitions]['weights']\n",
    "                                poids_total = np.sum(poids)\n",
    "                                poids = poids/poids_total\n",
    "                                poids = np.cumsum(poids)\n",
    "                                choix = random.random()\n",
    "                                for j in range(len(poids)):\n",
    "                                    if choix <= poids[j]:\n",
    "                                        reward_total += self.states[current_state].reward # ----------\n",
    "                                        current_state = Transitions_without_action[transitions]['targets'][j]\n",
    "                                        break\n",
    "                    else:\n",
    "                        action_choisie = random.choice(actions_possibles)\n",
    "                        for transitions in Transitions_with_action:\n",
    "                            if Transitions_with_action[transitions]['action'] == action_choisie:\n",
    "                                poids = Transitions_with_action[transitions]['weights']\n",
    "                                poids_total = np.sum(poids)\n",
    "                                poids = poids/poids_total\n",
    "                                poids = np.cumsum(poids)\n",
    "                                choix = random.random()\n",
    "                                for j in range(len(poids)):\n",
    "                                    if choix <= poids[j]:\n",
    "                                        reward_total += self.states[current_state].reward # ----------\n",
    "                                        current_state = Transitions_with_action[transitions]['targets'][j]\n",
    "                                        break\n",
    "                                    \n",
    "                    self.afficher(etat = current_state, file_name='image'+str(i+1))\n",
    "                    images.append(imageio.imread('image'+str(i+1)+'.png'))\n",
    "        imageio.mimsave(file_name+'.gif', images,fps=3)\n",
    "        for i in range(n_iter+1):\n",
    "            os.remove('image'+str(i)+'.png')\n",
    "        for i in range(n_iter+1):\n",
    "                os.remove('image'+str(i))\n",
    "\n",
    "        print(f\"Reward total : {reward_total}\")\n",
    "        \n",
    "        return current_state\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"States : {self.states} \\n Actions : {self.actions}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A faire : corriger soi-même le modèle pour qu'il soit lisible et qu'il puisse ensuite tourner (déclarer un état s'il ne l'est pas mais utilisé, faire une flèche reflexive si un état n'est pas utilisé...)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mettre random directement dans parcours (le choix sera fait par un input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States: ['S0', 'S1', 'S2', 'S3', 'S4']\n",
      "Actions: ['None']\n",
      "Transition from S0 with no action and targets ['S1', 'S2'] with weights [5, 5]\n",
      "Transition from S1 with no action and targets ['S0', 'S3'] with weights [5, 5]\n",
      "Transition from S3 with no action and targets ['S3'] with weights [10]\n",
      "Transition from S2 with no action and targets ['S4'] with weights [10]\n",
      "Transition from S4 with no action and targets ['S1'] with weights [10]\n",
      "{'States': ['S0', 'S1', 'S2', 'S3', 'S4'], 'Actions': ['None'], 'Transitions_with_action': {}, 'Transitions_without_action': {0: {'from': 'S0', 'targets': ['S1', 'S2'], 'weights': [5, 5]}, 1: {'from': 'S1', 'targets': ['S0', 'S3'], 'weights': [5, 5]}, 2: {'from': 'S3', 'targets': ['S3'], 'weights': [10]}, 3: {'from': 'S2', 'targets': ['S4'], 'weights': [10]}, 4: {'from': 'S4', 'targets': ['S1'], 'weights': [10]}}}\n",
      "--------------------------------------------------\n",
      " \n",
      "Warning : une action est déclarée mais n'est pas utilisée\n",
      "\n",
      " Écrire ok pour contiuer\n",
      "-------------------------\n",
      "\n",
      "Souhaitez-vous ajouter des récompenses aux états ? (y/n)\n",
      " \n",
      "Pour lancer un parcours, lancez M.parcours()\n",
      "Quel mode de parcours voulez-vous ?\n",
      "1 : sans actions\n",
      "2 : avec adversaire positionnel\n",
      "3 : avec adversaire non positionnel\n",
      "Combien d'étapes voulez-vous faire ?\n",
      "--------------------------------------------------\n",
      "| Etat actif : S0                                |\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "| Etat actif : S2                                |\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "| Etat actif : S4                                |\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "| Etat actif : S1                                |\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "| Etat actif : S0                                |\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "| Etat actif : S1                                |\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "| Etat actif : S0                                |\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "| Etat actif : S1                                |\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "| Etat actif : S3                                |\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "| Etat actif : S3                                |\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Reward total : 0\n",
      "Le graphique est visible dans le fichier visu_parcours.gif\n"
     ]
    }
   ],
   "source": [
    "M = markov(fichier_mdp=\"chaine_1.mdp\")\n",
    "M.parcours()\n",
    "# M.simulation_random(10, mode_adv = \"random\")\n",
    "\n",
    "# Le graphe est visible dans le fichier visu_parcours.gif\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TP1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "40f7c2dd250ea64d1f119704b8cfa97c376b5923eda5d57d2493e68729089b32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
