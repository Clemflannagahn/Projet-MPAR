{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problème pour les prints et les input sous VSCode, il faut ouvrir le notebook avec jupyter directement (dès fois ça marche quand même sous VS Code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Problème réglé en mettant des time.sleep(0.5) après les input pour laisser le temps d'afficher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdp\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States: ['S0', 'S1', 'S2']\n",
      "Actions: ['a', 'b', 'c']\n",
      "Transition from S0 with no action and targets ['S1', 'S2'] with weights [5, 5]\n",
      "Transition from S1 with action b and targets ['S1', 'S0'] with weights [2, 8]\n",
      "Transition from S1 with action a and targets ['S2', 'S0', 'S1'] with weights [1, 3, 6]\n",
      "Transition from S2 with action c and targets ['S0', 'S1'] with weights [5, 5]\n",
      "{'States': ['S0', 'S1', 'S2'], 'Actions': ['a', 'b', 'c'], 'Transitions_with_action': {1: {'from': 'S1', 'action': 'b', 'targets': ['S1', 'S0'], 'weights': [2, 8]}, 2: {'from': 'S1', 'action': 'a', 'targets': ['S2', 'S0', 'S1'], 'weights': [1, 3, 6]}, 3: {'from': 'S2', 'action': 'c', 'targets': ['S0', 'S1'], 'weights': [5, 5]}}, 'Transitions_without_action': {0: {'from': 'S0', 'targets': ['S1', 'S2'], 'weights': [5, 5]}}}\n"
     ]
    }
   ],
   "source": [
    "! python mdp.py < ex.mdp\n",
    "# ! python mdp.py < chaine_1.mdp\n",
    "# ! python mdp.py < ex_erreur.mdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données récupérées {'States': ['S0', 'S1', 'S2'], 'Actions': ['a', 'b', 'c'], 'Transitions_with_action': {1: {'from': 'S1', 'action': 'b', 'targets': ['S1', 'S0'], 'weights': [2, 8]}, 2: {'from': 'S1', 'action': 'a', 'targets': ['S2', 'S0', 'S1'], 'weights': [1, 3, 6]}, 3: {'from': 'S2', 'action': 'c', 'targets': ['S0', 'S1'], 'weights': [5, 5]}}, 'Transitions_without_action': {0: {'from': 'S0', 'targets': ['S1', 'S2'], 'weights': [5, 5]}}}\n"
     ]
    }
   ],
   "source": [
    "# On lit le .pickle des données que l'on souhaitent récupérer\n",
    "\n",
    "# Read list to memory\n",
    "def read_list(nom_liste):\n",
    "    # for reading also binary mode is important\n",
    "    with open(nom_liste, 'rb') as fp:\n",
    "        liste = pickle.load(fp)\n",
    "        return liste\n",
    "\n",
    "L = read_list(\"liste_donnees\")\n",
    "print('Données récupérées', L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States: ['S0', 'S1', 'S2']\n",
      "Actions: ['a', 'b', 'c']\n",
      "Transition with action: {'from': 'S1', 'action': 'b', 'targets': ['S1', 'S0'], 'weights': [2, 8]}\n",
      "Transition with action: {'from': 'S1', 'action': 'a', 'targets': ['S2', 'S0', 'S1'], 'weights': [1, 3, 6]}\n",
      "Transition with action: {'from': 'S2', 'action': 'c', 'targets': ['S0', 'S1'], 'weights': [5, 5]}\n",
      "Transition without action: {'from': 'S0', 'targets': ['S1', 'S2'], 'weights': [5, 5]}\n"
     ]
    }
   ],
   "source": [
    "print('States:', L['States'])\n",
    "print('Actions:', L['Actions'])\n",
    "for transitions in L['Transitions_with_action']:\n",
    "    print('Transition with action' ':', L['Transitions_with_action'][transitions])\n",
    "for transitions in L['Transitions_without_action']:\n",
    "    print('Transition without action' ':', L['Transitions_without_action'][transitions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import graphviz as gv\n",
    "import imageio\n",
    "import os\n",
    "import imageio.v2 as imageio\n",
    "\n",
    "class States():\n",
    "    def __init__(self, state, id,transitions_with_action, transitions_without_action):\n",
    "        \"\"\"\n",
    "        Initialisation des états de la chaine de markov\n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        state : str\n",
    "            Nom de l'état (S0...)\n",
    "        reward : int\n",
    "            Récompense de l'état\n",
    "        transitions_with_action : dict\n",
    "            Dictionnaire de l'ensemble des transitions avec action\n",
    "        transitions_without_action : dict\n",
    "            Dictionnaire de l'ensemble des transitions sans action\n",
    "        \"\"\"\n",
    "        self.state = state\n",
    "        self.reward = 0 # récompense de l'état\n",
    "        self.transitions_without_action = {}\n",
    "        self.transitions_with_action = {}\n",
    "\n",
    "        sans_action = True # on crée ce booléen pour vérifier qu'il n'y a pas de transition avec action ensuite\n",
    "        for transition in transitions_without_action:\n",
    "            # on parcours l'ensemble des transitions\n",
    "            transi_active = transitions_without_action[transition]\n",
    "            if transi_active[\"from\"]==self.state: # on vérifie si l'état de départ est l'état actif\n",
    "                sans_action = False\n",
    "                self.transitions_without_action[\"targets\"] = transi_active[\"targets\"]\n",
    "                self.transitions_without_action[\"weights\"] = transi_active[\"weights\"]\n",
    "\n",
    "        for transition in transitions_with_action:\n",
    "            transi_active = transitions_with_action[transition]\n",
    "            if transi_active[\"from\"]==self.state and sans_action == True:\n",
    "                # les clés dans transition_with_action sont les actions et les valeurs des dict des états cibles et leurs poids\n",
    "                self.transitions_with_action[transi_active[\"action\"]] = {\"targets\" : transi_active[\"targets\"], \"weights\" : transi_active[\"weights\"]}\n",
    "            elif transi_active[\"from\"]==self.state and sans_action == False:\n",
    "                print(\"\\nWarning : l'état\", self.state, \"comporte des transitions avec et sans action\")\n",
    "                print(\"Il est donc impossible de déterminer la transition à effectuer, il faut revoir la modélisation \\n\")\n",
    "                break\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"State : {self.state} \\n State reward {self.reward} \\n Transitions without action : {self.transitions_without_action} \\n Transitions with action : {self.transitions_with_action}\")\n",
    "\n",
    "\n",
    "class markov():\n",
    "    def __init__(self, states, actions, transitions_with_action, transitions_without_action):\n",
    "        \"\"\"\n",
    "        Initialisation de la chaine de markov\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        states : list\n",
    "            Liste des états de la chaine (définis avec la calsse States)\n",
    "        listes_states : list\n",
    "            Liste des noms états de la chaines (avec possiblement des doublons)\n",
    "        actions : list\n",
    "            Liste des actions possibles\n",
    "        transitions_with_action : dict\n",
    "            Dictionnaire de l'ensemble des transitions avec action\n",
    "        transitions_without_action : dict\n",
    "            Dictionnaire de l'ensemble des transitions sans action\n",
    "        \"\"\"\n",
    "        self.states = {}\n",
    "        self.liste_states = states\n",
    "        self.actions = actions\n",
    "        self.transitions_with_action = transitions_with_action\n",
    "        self.transitions_without_action = transitions_without_action\n",
    "\n",
    "        for state in states:\n",
    "            self.states[f\"{state}\"] = States(state, states.index(state), transitions_with_action, transitions_without_action)\n",
    "        \n",
    "        markov.parsing(self, states) # on vérifie qu'on a pas de problèmes de parsing\n",
    "\n",
    "        print(\"Souhaitez-vous ajouter des récompenses aux états ? (y/n)\")\n",
    "        time.sleep(0.5)\n",
    "        reponse = input()\n",
    "        if reponse == \"y\":\n",
    "            for state in self.states :\n",
    "                etat = self.states[state]\n",
    "                reward = markov.affichage_etat(self, etat, reward = True)\n",
    "                etat.reward = float(reward)\n",
    "        \n",
    "    def parsing(self, states):\n",
    "        \"\"\"\n",
    "        On réalise différents tests pour vérifier que la chaine de markov (ou la MDP) est correctement définie\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        states : list\n",
    "            Liste des états de la chaines (avec possiblement des doublons)\n",
    "        \"\"\"\n",
    "        # On concatène les transitions avec et sans action pour plus de simplicité pour les test\n",
    "        Warning = False # passe à True si on a un warning\n",
    "\n",
    "        all_transitions = []\n",
    "        transitions_without_action = []\n",
    "        transitions_with_action = []\n",
    "        for elem in self.transitions_without_action:\n",
    "            transitions_without_action.append(self.transitions_without_action[elem])\n",
    "            all_transitions.append(self.transitions_without_action[elem])\n",
    "        for elem in self.transitions_with_action:\n",
    "            transitions_with_action.append(self.transitions_with_action[elem])\n",
    "            all_transitions.append(self.transitions_with_action[elem])\n",
    "\n",
    "        # On vérifie que les états déclarés sont utilisés et qu'un état utilisé dans des transitions est déclaré\n",
    "        used_states = []\n",
    "        for transitions in all_transitions:\n",
    "            if transitions[\"from\"] not in self.states:\n",
    "                print(f\"Warning : l'état {transitions['from']} est utilisé dans une transition mais n'est pas déclaré\")\n",
    "                Warning = True\n",
    "            used_states.append(transitions[\"from\"])\n",
    "            used_states.append(transitions[\"targets\"])\n",
    "            for target in transitions[\"targets\"]:\n",
    "                if target not in self.states:\n",
    "                    print(f\"Warning : l'état {target} est utilisé dans une transition mais n'est pas déclaré\")\n",
    "                    Warning = True\n",
    "        for state in self.states:\n",
    "            if state not in used_states:\n",
    "                print(f\"Warning : l'état {state} est déclaré mais n'est pas utilisé\")\n",
    "                Warning = True\n",
    "\n",
    "        # On vérifie qu'un état n'est pas déclaré plusieurs fois\n",
    "        if len(states) != len(self.states): # self.states supprime automatiquement les doublons\n",
    "            print(\"Warning : un état est déclaré plusieurs fois\")\n",
    "            Warning = True\n",
    "\n",
    "        # On vérifie qu'un état possède bien une transition de sortie\n",
    "        etats_sans_sortie = []\n",
    "        dict_etats = self.states\n",
    "        bool_etat_sans_sortie = False\n",
    "        for state in dict_etats:\n",
    "            if dict_etats[state].transitions_without_action == {} and dict_etats[state].transitions_with_action == {}:\n",
    "                etats_sans_sortie.append(state)\n",
    "                bool_etat_sans_sortie = True\n",
    "        if bool_etat_sans_sortie == True:\n",
    "            print(\"Warning : les états suivants n'ont pas de transition de sortie : \", etats_sans_sortie)\n",
    "\n",
    "        # On vérifie que les actions ne sont pas déclarées plusieurs fois\n",
    "        actions_uniques = set(self.actions)\n",
    "        if len(actions_uniques) != len(self.actions):\n",
    "            print(\"Warning : une action est déclarée plusieurs fois\")\n",
    "            Warning = True\n",
    "    \n",
    "        # On vérifie qu'une action déclarée est utilisée\n",
    "        actions_utilisés = []\n",
    "        for transitions in transitions_with_action:\n",
    "            actions_utilisés.append(transitions[\"action\"])\n",
    "        actions_utilisés = set(actions_utilisés) # on enlève les doublons\n",
    "        if len(actions_utilisés) != len(self.actions):\n",
    "            print(\"Warning : une action est déclarée mais n'est pas utilisée\")\n",
    "            Warning = True\n",
    "\n",
    "        # On vérifie que les actions utilisées sont déclarées\n",
    "        for action in actions_utilisés:\n",
    "            if action not in self.actions:\n",
    "                print(f\"Warning : l'action {action} est utilisée mais n'est pas déclarée\")\n",
    "                Warning = True\n",
    "\n",
    "        if Warning :\n",
    "            print(\"\\n Écrire ok pour contiuer\")\n",
    "            print(\"-\"*25 + \"\\n\")\n",
    "            while True:\n",
    "                rep = input()\n",
    "                if rep == \"ok\":\n",
    "                    break\n",
    "            \n",
    "    def affichage_etat(self,etat_actif,choix = False, reward = False):\n",
    "        \"\"\"\n",
    "        Affiche proprement l'état actif de la chaine de markov et permet de choisir une action le cas échéant\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        etat_actif : état de la chaine de markov\n",
    "            Etat actif de la chaine de markov\n",
    "        choix : bool\n",
    "            Si on doit afficher des choix pour des actions\n",
    "        \"\"\"\n",
    "        nom = etat_actif.state\n",
    "        print(\"-\"*50)\n",
    "        chaine_nom = f\"| Etat actif : {nom}\"\n",
    "        l = len(chaine_nom)\n",
    "        print(chaine_nom + \" \"*(49-l) + \"|\")\n",
    "        if choix :\n",
    "            chaine_choix = f\"| choix possibles pour l'état {etat_actif.state}:\"\n",
    "            l = len(chaine_choix)\n",
    "            print(chaine_choix + \" \"*(49-l) + \"|\")\n",
    "\n",
    "            chaine_transi = f\"| {list(etat_actif.transitions_with_action.keys())}\"\n",
    "            l = len(chaine_transi)\n",
    "            print(chaine_transi + \" \"*(49-l) + \"|\")\n",
    "\n",
    "            chaine_action = f\"| choix de l'action  :\"\n",
    "            l = len(chaine_action)\n",
    "            print(chaine_action + \" \"*(49-l) + \"|\")\n",
    "            time.sleep(0.5)\n",
    "            choix = input()\n",
    "            while choix not in list(etat_actif.transitions_with_action.keys()): # on vérifie que l'action choisie est valide\n",
    "                choix = input()\n",
    "                if choix == \"stop\": # permet d'arrêter le programme à la main\n",
    "                    break\n",
    "            chaine_choix = f\"| Vous avez choisi l'action {choix}\"\n",
    "            l = len(chaine_choix)\n",
    "            print(chaine_choix + \" \"*(49-l) + \"|\")\n",
    "\n",
    "        elif reward:\n",
    "            chaine_choix = f\"| Récompense pour l'état {etat_actif.state}:\"\n",
    "            l = len(chaine_choix)\n",
    "            print(chaine_choix + \" \"*(49-l) + \"|\")\n",
    "            time.sleep(0.5)\n",
    "            choix = input()\n",
    "            chaine_rec = f\"| Vous avez choisi : {choix}\"\n",
    "            l = len(chaine_rec)\n",
    "            print(chaine_rec + \" \"*(49-l) + \"|\")\n",
    "\n",
    "            \n",
    "        print(\"-\"*50)\n",
    "        print(\"\\n\")   \n",
    "        return choix    \n",
    "\n",
    "    def parcours(self,N, without_action = False, positionnel = False, n_pos = False, file_name=\"visu_parcours\"): # on parcours la chaine (en faisant N étapes)\n",
    "        \"\"\" \n",
    "        On parcours la chaine en faisant N étapes\n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        N : int\n",
    "            Nombre d'étapes\n",
    "        without_action : bool\n",
    "            Si on fait un parcours sans actions (c'est à dire que la chaine ne possède pas d'actions)\n",
    "        positionnel : bool\n",
    "            Si on fait un parcours avec un adversaire positionnel\n",
    "        n_pos : int\n",
    "            Si on fait un parcours avec un adversaire non positionnel\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "        etat_initial = self.liste_states[0] #état initial : premier élément\n",
    "        etat_actif = self.states[etat_initial] # on prend l'objet correspondant à l'état initial\n",
    "        reward_total = 0\n",
    "        \n",
    "        self.afficher(etat = etat_initial, file_name='image0')\n",
    "        images = []\n",
    "        images.append(imageio.imread('image0'+'.png'))\n",
    "\n",
    "        if without_action:\n",
    "        # On vérifie qu'on ne choisit pas le mode \"sans actions\" alors qu'il y en a\n",
    "            for state in self.states:\n",
    "                if len(self.states[state].transitions_with_action) != 0:\n",
    "                    print(\"Error : il y a des transitions avec actions, il faut choisir le mode avec actions\")\n",
    "                    return\n",
    "\n",
    "\n",
    "            for i in range(N):\n",
    "                markov.affichage_etat(self, etat_actif)\n",
    "                # print(etat_actif.state) # on affiche l'état en cours\n",
    "                poids = etat_actif.transitions_without_action[\"weights\"]\n",
    "                poids_total = np.sum(poids)\n",
    "                poids = poids/poids_total # on normalise les poids pour qu'ils soient entre 0 et 1\n",
    "                poids = np.cumsum(poids) # on fait la somme cumulée des poids, afin de pouvoir faire un tirage aléatoire (il ne faut pas que par exemple les deux probas soient de 0.5, il en faut une de 0.5 et l'autre de 1)\n",
    "\n",
    "                choix = random.random() # tirage aléatoire entre 0 et 1\n",
    "\n",
    "                for j in range(len(poids)): # on recherche l'état cible\n",
    "                    if choix <= poids[j]:\n",
    "                        reward_total += etat_actif.reward\n",
    "                        etat_actif = self.states[etat_actif.transitions_without_action[\"targets\"][j]]\n",
    "                        break\n",
    "                self.afficher(etat = etat_actif.state, file_name='image'+str(i+1))\n",
    "                images.append(imageio.imread('image'+str(i+1)+'.png'))\n",
    "            # create gif\n",
    "            imageio.mimsave(file_name+'.gif', images, fps=3)\n",
    "            for i in range(N+1):\n",
    "                os.remove('image'+str(i)+'.png')\n",
    "\n",
    "        elif positionnel == True or n_pos == True: # adversaire positionnel\n",
    "            if positionnel :\n",
    "                print(\"Choix d'un adversaire positionnel\")\n",
    "                adv_pos = {} # contient pour chaque état, le choix de l'adversaire\n",
    "                for state in self.states :\n",
    "                    etat = self.states[state]\n",
    "                    if etat.transitions_with_action != {} : # si l'état possèdes des transitions avec actions\n",
    "                        action = markov.affichage_etat(self, etat, choix = True)\n",
    "                        adv_pos[state] = action\n",
    "\n",
    "            for i in range(N):\n",
    "                if etat_actif.transitions_with_action == {} : # si l'état n'a pas de transitions avec actions :\n",
    "                    markov.affichage_etat(self, etat_actif)\n",
    "                    poids = etat_actif.transitions_without_action[\"weights\"]\n",
    "\n",
    "                    poids_total = np.sum(poids)\n",
    "                    poids = poids/poids_total # on normalise les poids pour qu'ils soient entre 0 et 1\n",
    "                    poids = np.cumsum(poids) # on fait la somme cumulée des poids, afin de pouvoir faire un tirage aléatoire (il ne faut pas que par exemple les deux probas soient de 0.5, il en faut une de 0.5 et l'autre de 1)\n",
    "\n",
    "                    choix = random.random() # tirage aléatoire entre 0 et 1\n",
    "\n",
    "                    for j in range(len(poids)): # on recherche l'état cible\n",
    "                        if choix <= poids[j]:\n",
    "                            reward_total += etat_actif.reward\n",
    "                            etat_actif = self.states[etat_actif.transitions_without_action[\"targets\"][j]]\n",
    "                            break\n",
    "                else :\n",
    "                    if n_pos == True :\n",
    "                        action_choisie = markov.affichage_etat(self, etat_actif, choix =True)\n",
    "                    else :\n",
    "                        action_choisie = adv_pos[etat_actif.state]\n",
    "                        print(f\"Action choisie : {action_choisie}\")\n",
    "                        markov.affichage_etat(self, etat_actif)\n",
    "                    poids = etat_actif.transitions_with_action[action_choisie][\"weights\"] # on ne prend que les poids de l'action choisie par l'adversaire\n",
    "                    poids_total = np.sum(poids)\n",
    "                    poids = poids/poids_total # on normalise les poids pour qu'ils soient entre 0 et 1\n",
    "                    poids = np.cumsum(poids) # on fait la somme cumulée des poids, afin de pouvoir faire un tirage aléatoire (il ne faut pas que par exemple les deux probas soient de 0.5, il en faut une de 0.5 et l'autre de 1)\n",
    "\n",
    "                    choix = random.random() # tirage aléatoire entre 0 et 1\n",
    "\n",
    "                    for j in range(len(poids)): # on recherche l'état cible\n",
    "                        if choix <= poids[j]:\n",
    "                            reward_total += etat_actif.reward\n",
    "                            etat_actif = self.states[etat_actif.transitions_with_action[action_choisie][\"targets\"][j]]\n",
    "                            break\n",
    "                        \n",
    "                self.afficher(etat = etat_actif.state, file_name='image'+str(i+1))\n",
    "                images.append(imageio.imread('image'+str(i+1)+'.png'))\n",
    "            # create gif\n",
    "            imageio.mimsave(file_name+'.gif', images, fps=3)\n",
    "            for i in range(N+1):\n",
    "                os.remove('image'+str(i)+'.png')\n",
    "            for i in range(N+1):\n",
    "                os.remove('image'+str(i))\n",
    "                \n",
    "        print(f\"Reward total : {reward_total}\")\n",
    "\n",
    "    \n",
    "    def afficher(self, etat = \"default\", file_name = \"graph\"):\n",
    "        \n",
    "        \"\"\"Fonction qui permet de représenter le graphe de la chaine de Markov avec ou sans action. Dans le mode \"default\", le graphe de base est affiché.\n",
    "        Dans le mode \"etat\", on peut choisir un état et il sera mis en évidence en étant de couleur bleue.\n",
    "         \"\"\"\n",
    "    \n",
    "        # On récupère les données\n",
    "        States = self.states\n",
    "        Actions = self.actions\n",
    "        Transitions_with_action = self.transitions_with_action\n",
    "        Transitions_without_action = self.transitions_without_action\n",
    "\n",
    "        # On crée le graphique\n",
    "        G = gv.Digraph(format='png')\n",
    "\n",
    "        if etat == \"default\":\n",
    "            for state in States:\n",
    "                G.node(state)\n",
    "        else:\n",
    "            for state in States:\n",
    "                if state == etat:\n",
    "                    G.node(state, color = 'blue', style = 'filled')\n",
    "                else:\n",
    "                    G.node(state)\n",
    "        \n",
    "        #On ajoute les actions\n",
    "        for actions in Actions:\n",
    "            G.node(actions, shape = 'point')\n",
    "            \n",
    "        for transition in Transitions_with_action:\n",
    "            G.edge(Transitions_with_action[transition]['from'], Transitions_with_action[transition]['action'], label=str(Transitions_with_action[transition]['action']), color = 'red')\n",
    "        \n",
    "\n",
    "        # On ajoute les transitions sans action\n",
    "        for transition in Transitions_without_action:\n",
    "            for i in range(len(Transitions_without_action[transition]['targets'])):\n",
    "                G.edge(Transitions_without_action[transition]['from'],Transitions_without_action[transition]['targets'][i], label = str(Transitions_without_action[transition]['weights'][i])) \n",
    "\n",
    "        # On ajoute les transitions avec action\n",
    "        for transition in Transitions_with_action:\n",
    "            for i in range(len(Transitions_with_action[transition]['targets'])):\n",
    "                G.edge(Transitions_with_action[transition]['action'],Transitions_with_action[transition]['targets'][i], label = str(Transitions_with_action[transition]['weights'][i]))\n",
    "        \n",
    "        G.render(file_name, view=False)\n",
    "    \n",
    "    def simulation_random(self, n_iter, initial_state= \"S0\", mode_adv = \"random\" ):\n",
    "        \"\"\" Fonction qui permet de simuler une chaine de Markov avec ou sans action. On peut choisir le nombre d'itération, l'état initial et le mode de l'adversaire.\n",
    "        Pour l'instant, seul le mode \"random\" est disponible.\"\"\"\n",
    "        \n",
    "        current_state = initial_state\n",
    "        States = self.states\n",
    "        Actions = self.actions\n",
    "        Transitions_with_action = self.transitions_with_action\n",
    "        Transitions_without_action = self.transitions_without_action\n",
    "        self.afficher(etat = current_state, file_name='image0')\n",
    "        reward_total = 0\n",
    "        images = []\n",
    "        if mode_adv == \"random\":\n",
    "            for i in range(n_iter):\n",
    "                    actions_possibles = []\n",
    "                    for transitions in Transitions_with_action:\n",
    "                        if Transitions_with_action[transitions]['from'] == current_state:\n",
    "                            actions_possibles.append(Transitions_with_action[transitions]['action'])\n",
    "                    if len(actions_possibles) == 0:\n",
    "                        for transitions in Transitions_without_action:\n",
    "                            if Transitions_without_action[transitions]['from'] == current_state:\n",
    "                                poids = Transitions_without_action[transitions]['weights']\n",
    "                                poids_total = np.sum(poids)\n",
    "                                poids = poids/poids_total\n",
    "                                poids = np.cumsum(poids)\n",
    "                                choix = random.random()\n",
    "                                for j in range(len(poids)):\n",
    "                                    if choix <= poids[j]:\n",
    "                                        reward_total += self.states[current_state].reward # ----------\n",
    "                                        current_state = Transitions_without_action[transitions]['targets'][j]\n",
    "                                        break\n",
    "                    else:\n",
    "                        action_choisie = random.choice(actions_possibles)\n",
    "                        for transitions in Transitions_with_action:\n",
    "                            if Transitions_with_action[transitions]['action'] == action_choisie:\n",
    "                                poids = Transitions_with_action[transitions]['weights']\n",
    "                                poids_total = np.sum(poids)\n",
    "                                poids = poids/poids_total\n",
    "                                poids = np.cumsum(poids)\n",
    "                                choix = random.random()\n",
    "                                for j in range(len(poids)):\n",
    "                                    if choix <= poids[j]:\n",
    "                                        reward_total += self.states[current_state].reward # ----------\n",
    "                                        current_state = Transitions_with_action[transitions]['targets'][j]\n",
    "                                        break\n",
    "                                    \n",
    "                    self.afficher(etat = current_state, file_name='image'+str(i+1))\n",
    "                    images.append(imageio.imread('image'+str(i+1)+'.png'))\n",
    "        imageio.mimsave('simulation.gif', images,fps=3)\n",
    "        for i in range(n_iter+1):\n",
    "            os.remove('image'+str(i)+'.png')\n",
    "        for i in range(n_iter+1):\n",
    "                os.remove('image'+str(i))\n",
    "\n",
    "        print(f\"Reward total : {reward_total}\")\n",
    "        \n",
    "        return current_state\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f\"States : {self.states} \\n Actions : {self.actions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Souhaitez-vous ajouter des récompenses aux états ? (y/n)\n",
      "--------------------------------------------------\n",
      "| Etat actif : S0                                |\n",
      "| Récompense pour l'état S0:                     |\n",
      "| Vous avez choisi : 7                           |\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "| Etat actif : S1                                |\n",
      "| Récompense pour l'état S1:                     |\n",
      "| Vous avez choisi : 8                           |\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "| Etat actif : S2                                |\n",
      "| Récompense pour l'état S2:                     |\n",
      "| Vous avez choisi : 9                           |\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Reward total : 78.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'S1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# States(L['States'][1], 0, L['Transitions_with_action'], L['Transitions_without_action'])\n",
    "\n",
    "M = markov(L['States'], L['Actions'], L['Transitions_with_action'], L['Transitions_without_action'])\n",
    "\n",
    "#M.afficher()\n",
    "# M.parcours(10, positionnel=True)\n",
    "# M.parcours(10, without_action=True)\n",
    "M.simulation_random(10, initial_state = \"S0\", mode_adv = \"random\")\n",
    "\n",
    "# Le graphe est visible dans le fichier visu_parcours.gif\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "import copy\n",
    "\n",
    "def simulation(L, n_iter, initial_state= \"S0\", mode_adv = \"random\" ):\n",
    "    current_state = initial_state\n",
    "    States = L['States']\n",
    "    Actions = L['Actions']\n",
    "    Transitions_with_action = L['Transitions_with_action']\n",
    "    Transitions_without_action = L['Transitions_without_action']\n",
    "    G = afficher(L, etat = current_state)\n",
    "    G.render('image0')\n",
    "    images = []\n",
    "    if mode_adv == \"random\":\n",
    "        for i in range(n_iter):\n",
    "                actions_possibles = []\n",
    "                for transitions in Transitions_with_action:\n",
    "                    if Transitions_with_action[transitions]['from'] == current_state:\n",
    "                        actions_possibles.append(Transitions_with_action[transitions]['action'])\n",
    "                if len(actions_possibles) == 0:\n",
    "                    for transitions in Transitions_without_action:\n",
    "                        if Transitions_without_action[transitions]['from'] == current_state:\n",
    "                            poids = Transitions_without_action[transitions]['weights']\n",
    "                            poids_total = np.sum(poids)\n",
    "                            poids = poids/poids_total\n",
    "                            poids = np.cumsum(poids)\n",
    "                            choix = random.random()\n",
    "                            for j in range(len(poids)):\n",
    "                                if choix <= poids[j]:\n",
    "                                    current_state = Transitions_without_action[transitions]['targets'][j]\n",
    "                                    break\n",
    "                else:\n",
    "                    action_choisie = random.choice(actions_possibles)\n",
    "                    for transitions in Transitions_with_action:\n",
    "                        if Transitions_with_action[transitions]['action'] == action_choisie:\n",
    "                            poids = Transitions_with_action[transitions]['weights']\n",
    "                            poids_total = np.sum(poids)\n",
    "                            poids = poids/poids_total\n",
    "                            poids = np.cumsum(poids)\n",
    "                            choix = random.random()\n",
    "                            for j in range(len(poids)):\n",
    "                                if choix <= poids[j]:\n",
    "                                    current_state = Transitions_with_action[transitions]['targets'][j]\n",
    "                                    break\n",
    "                                \n",
    "                G = afficher(L, etat = current_state)\n",
    "                G.render('image'+str(i+1))\n",
    "                images.append(imageio.imread('image'+str(i+1)+'.png'))\n",
    "    imageio.mimsave('simulation.gif', images,fps=3)\n",
    "    for i in range(n_iter):\n",
    "        os.remove('image'+str(i)+'.png')\n",
    "    return current_state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation(L, 10, mode_adv = \"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.drawing.nx_agraph import to_agraph\n",
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "import copy\n",
    "def visu_animation(L):\n",
    "  # Do not modify original data\n",
    "  L_2 = copy.deepcopy(L)\n",
    "  #Markov chain parameters\n",
    "  states = []\n",
    "  for i in range (len(L_2['States'])):\n",
    "    states.append(i)\n",
    "  \n",
    "  for i in range (len(L_2['States'])):\n",
    "      for j in range(len(L_2['Transitions_without_action'][i]['targets'])):\n",
    "        L_2['Transitions_without_action'][i]['targets'][j]= int(L_2['Transitions_without_action'][i]['targets'][j][1:])\n",
    "  print(L_2['Transitions_without_action'])\n",
    "        \n",
    "\n",
    "  Q = []\n",
    "  for i in range (len(L_2['States'])):\n",
    "    Q.append([])\n",
    "    for j in range (len(L_2['States'])):\n",
    "      if j not in L_2['Transitions_without_action'][i]['targets']:\n",
    "        Q[i].append(0)\n",
    "      else : \n",
    "        Q[i].append(L_2['Transitions_without_action'][i]['weights'][L_2['Transitions_without_action'][i]['targets'].index(j)]/sum(L_2['Transitions_without_action'][i]['weights']))\n",
    "\n",
    "\n",
    "  #Sampling the markov chain over 100 steps\n",
    "  N_steps=20\n",
    "  node_ind=0\n",
    "  node_sel=[node_ind]\n",
    "  for i in range(N_steps):\n",
    "    temp_ni=np.random.choice(len(states),p=Q[node_ind])\n",
    "    node_sel.append(temp_ni)\n",
    "    node_ind=temp_ni\n",
    "\n",
    "  #Setting up network\n",
    "  G = nx.MultiDiGraph()\n",
    "  [G.add_node(s,style='filled',fillcolor='white',shape='circle',fixedsize='true',width=0.5) for s in states]\n",
    "\n",
    "  labels={}\n",
    "  edge_labels={}\n",
    "\n",
    "  for i, origin_state in enumerate(states):\n",
    "      for j, destination_state in enumerate(states):\n",
    "          rate = Q[i][j]\n",
    "          if rate > 0:\n",
    "              G.add_edge(origin_state, destination_state, weight=rate, label=\"{:.02f}\".format(rate),len=2)\n",
    "  \n",
    "  #Setting up node color for each iteration     \n",
    "  for k in range(N_steps):\n",
    "    for i,n in enumerate(G.nodes(data=True)):\n",
    "      if i==node_sel[k]:\n",
    "        n[1]['fillcolor']='blue'\n",
    "      else:\n",
    "        n[1]['fillcolor']='white'\n",
    "      \n",
    "    A = to_agraph(G)\n",
    "    A.layout()\n",
    "    A.draw('net_'+str(k)+'.png')\n",
    "\n",
    "  #Create gif with imageio\n",
    "  images = []\n",
    "  filenames=['net_'+str(k)+'.png' for k in range(N_steps)]\n",
    "  for filename in filenames:\n",
    "      images.append(imageio.imread(filename))\n",
    "  imageio.mimsave('markov_chain.gif', images,fps=3)\n",
    "  # Delete images\n",
    "  for filename in filenames:\n",
    "      os.remove(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visu_animation(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculer proba arriver dans un état final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_etat(L, initial_state, nb_iterations):   \n",
    "    # From an initial state, calculate the probability of being in each state after nb_iterations\n",
    "    # L : dictionnary of the markov chain\n",
    "    # initial_state : initial state\n",
    "    # nb_iterations : number of iterations\n",
    "    # return : dictionnary of the probability of being in each state after nb_iterations\n",
    "\n",
    "    # Initialisation\n",
    "    states = L['States']\n",
    "    transitions_without_action = L['Transitions_without_action']\n",
    "    \n",
    "    # Transform weights into probabilities\n",
    "    for transition in transitions_without_action:\n",
    "        transitions_without_action[transition]['weights'] = [weight / sum(transitions_without_action[transition]['weights']) for weight in transitions_without_action[transition]['weights']]\n",
    "        \n",
    "\n",
    "    # Probability of being in each state after nb_iterations\n",
    "    proba = {}\n",
    "    for state in states:\n",
    "        proba[state] = 0\n",
    "    proba[initial_state] = 1\n",
    "\n",
    "    # Calculate the probability of being in each state after nb_iterations\n",
    "    for i in range(nb_iterations):\n",
    "        for state in states:\n",
    "            proba[state] = sum([proba[transitions_without_action[transition]['from']] * transitions_without_action[transition]['weights'][i] for transition in transitions_without_action for i in range(len(transitions_without_action[transition]['targets'])) if transitions_without_action[transition]['targets'][i] == state])\n",
    "\n",
    "    return proba\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S0': 0.0, 'S1': 0.0, 'S2': 0.0, 'S3': 0.0, 'S4': 0.0}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcul_etat(L, 'S0', 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TP1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "40f7c2dd250ea64d1f119704b8cfa97c376b5923eda5d57d2493e68729089b32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
